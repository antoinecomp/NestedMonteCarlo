{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import csv \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28961, 256)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"data.csv\", 'r') as f:\n",
    "    plays = np.array(list(csv.reader(f, delimiter=\",\")))\n",
    "    print(plays.shape)    \n",
    "# We take the 126 first columns as input\n",
    "df = pd.DataFrame(data=plays[0:28961,1:256])\n",
    "# We take the 126 last columns as output\n",
    "Y = pd.DataFrame(data=plays[0:28961,129:256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['split'] = np.random.randn(df.shape[0], 1)\n",
    "msk = np.random.rand(len(df)) <= 0.7\n",
    "\n",
    "train_df = df[msk].fillna(\"sterby\")\n",
    "test_df = df[~msk].fillna(\"sterby\")\n",
    "\n",
    "# we take the 128 first columns has input\n",
    "X_train = train_df.iloc[:,0:128].values\n",
    "# we take the 128 last columns has input\n",
    "y_train = train_df.iloc[:,128:].values\n",
    "X_test = test_df.iloc[:,0:128].values\n",
    "Y_test = test_df.iloc[:,128:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our data type to float32 and normalize our data values to the range [0, 1].\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20257, 128)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "from keras import *\n",
    "from keras.layers import *\n",
    "\n",
    "\n",
    "# \n",
    "model = Sequential()\n",
    "#The input shape parameter should be the shape of 1 sample. In this case, it's the same (1, 28, 28) that corresponds to  the (depth, width, height) of each digit image.\n",
    "model.add(Conv1D(padding=\"valid\", input_shape=(128, 128), kernel_size=8, filters=32))\n",
    "#But what do the first 3 parameters represent?\n",
    "#They correspond to the number of convolution filters to use,\n",
    "# the number of rows in each convolution kernel, and the number of columns in each convolution kernel, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 121, 32)\n"
     ]
    }
   ],
   "source": [
    "#printing the shape of the current model output:\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more layers to our model like we're building legos\n",
    "model.add(Conv1D(32, 2, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(1)))\n",
    "# Dropout is a method for regularizing our model in order to prevent overfitting.\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So far, for model parameters, we've added two Convolution layers. \n",
    "# To complete our model architecture, let's add a fully connected layer and then the output layer:\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20257/20257 [==============================] - 4s 197us/step - loss: 141.2754 - acc: 0.0081\n",
      "Epoch 2/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 139.4344 - acc: 0.0388\n",
      "Epoch 3/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 139.1322 - acc: 0.0516\n",
      "Epoch 4/100\n",
      "20257/20257 [==============================] - 3s 137us/step - loss: 138.8849 - acc: 0.0597\n",
      "Epoch 5/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 138.6673 - acc: 0.0655\n",
      "Epoch 6/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 138.4566 - acc: 0.0796\n",
      "Epoch 7/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 138.2341 - acc: 0.1013\n",
      "Epoch 8/100\n",
      "20257/20257 [==============================] - 3s 137us/step - loss: 138.0356 - acc: 0.1110\n",
      "Epoch 9/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 137.8465 - acc: 0.1318\n",
      "Epoch 10/100\n",
      "20257/20257 [==============================] - 3s 139us/step - loss: 137.6476 - acc: 0.1648\n",
      "Epoch 11/100\n",
      "20257/20257 [==============================] - 3s 139us/step - loss: 137.4671 - acc: 0.1904\n",
      "Epoch 12/100\n",
      "20257/20257 [==============================] - 3s 137us/step - loss: 137.3060 - acc: 0.2344\n",
      "Epoch 13/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 137.1537 - acc: 0.2855\n",
      "Epoch 14/100\n",
      "20257/20257 [==============================] - 3s 141us/step - loss: 137.0137 - acc: 0.3310\n",
      "Epoch 15/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 136.8894 - acc: 0.3929\n",
      "Epoch 16/100\n",
      "20257/20257 [==============================] - 3s 137us/step - loss: 136.7877 - acc: 0.4737\n",
      "Epoch 17/100\n",
      "20257/20257 [==============================] - 3s 141us/step - loss: 136.6811 - acc: 0.5382\n",
      "Epoch 18/100\n",
      "20257/20257 [==============================] - 3s 139us/step - loss: 136.5839 - acc: 0.5484\n",
      "Epoch 19/100\n",
      "20257/20257 [==============================] - 3s 141us/step - loss: 136.5092 - acc: 0.5641\n",
      "Epoch 20/100\n",
      "20257/20257 [==============================] - 3s 137us/step - loss: 136.4332 - acc: 0.6082\n",
      "Epoch 21/100\n",
      "20257/20257 [==============================] - 3s 137us/step - loss: 136.3801 - acc: 0.6331\n",
      "Epoch 22/100\n",
      "20257/20257 [==============================] - 3s 138us/step - loss: 136.3317 - acc: 0.6441\n",
      "Epoch 23/100\n",
      "20257/20257 [==============================] - 3s 139us/step - loss: 136.2760 - acc: 0.6844\n",
      "Epoch 24/100\n",
      "20257/20257 [==============================] - 3s 139us/step - loss: 136.2286 - acc: 0.6845\n",
      "Epoch 25/100\n",
      "20257/20257 [==============================] - 3s 138us/step - loss: 136.1779 - acc: 0.7056\n",
      "Epoch 26/100\n",
      "20257/20257 [==============================] - 3s 140us/step - loss: 136.1457 - acc: 0.7072\n",
      "Epoch 27/100\n",
      "20257/20257 [==============================] - 3s 138us/step - loss: 136.1111 - acc: 0.7173\n",
      "Epoch 28/100\n",
      "20257/20257 [==============================] - 3s 138us/step - loss: 136.0897 - acc: 0.7260\n",
      "Epoch 29/100\n",
      "20257/20257 [==============================] - 3s 139us/step - loss: 136.0434 - acc: 0.7325\n",
      "Epoch 30/100\n",
      "20257/20257 [==============================] - 3s 140us/step - loss: 136.0329 - acc: 0.7405\n",
      "Epoch 31/100\n",
      "20257/20257 [==============================] - 3s 140us/step - loss: 136.0095 - acc: 0.7468\n",
      "Epoch 32/100\n",
      "20257/20257 [==============================] - 3s 141us/step - loss: 135.9852 - acc: 0.7507\n",
      "Epoch 33/100\n",
      "20257/20257 [==============================] - 3s 144us/step - loss: 135.9664 - acc: 0.7548\n",
      "Epoch 34/100\n",
      "20257/20257 [==============================] - 3s 139us/step - loss: 135.9442 - acc: 0.7686\n",
      "Epoch 35/100\n",
      "20257/20257 [==============================] - 3s 140us/step - loss: 135.9403 - acc: 0.7580\n",
      "Epoch 36/100\n",
      "20257/20257 [==============================] - 3s 138us/step - loss: 135.9112 - acc: 0.7609\n",
      "Epoch 37/100\n",
      "20257/20257 [==============================] - 3s 140us/step - loss: 135.8895 - acc: 0.7680\n",
      "Epoch 38/100\n",
      "20257/20257 [==============================] - 3s 140us/step - loss: 135.8739 - acc: 0.7664\n",
      "Epoch 39/100\n",
      "20257/20257 [==============================] - 3s 140us/step - loss: 135.8669 - acc: 0.7731\n",
      "Epoch 40/100\n",
      "20257/20257 [==============================] - 3s 142us/step - loss: 135.8553 - acc: 0.7671\n",
      "Epoch 41/100\n",
      "20257/20257 [==============================] - 3s 140us/step - loss: 135.8588 - acc: 0.7773\n",
      "Epoch 42/100\n",
      "20257/20257 [==============================] - 3s 141us/step - loss: 135.8365 - acc: 0.7789\n",
      "Epoch 43/100\n",
      "20257/20257 [==============================] - 3s 140us/step - loss: 135.8276 - acc: 0.7862\n",
      "Epoch 44/100\n",
      "20257/20257 [==============================] - 3s 140us/step - loss: 135.7988 - acc: 0.7778\n",
      "Epoch 45/100\n",
      "20257/20257 [==============================] - 3s 142us/step - loss: 135.8022 - acc: 0.7875\n",
      "Epoch 46/100\n",
      "20257/20257 [==============================] - 3s 141us/step - loss: 135.7844 - acc: 0.7883\n",
      "Epoch 47/100\n",
      "20257/20257 [==============================] - 3s 142us/step - loss: 135.7746 - acc: 0.7888\n",
      "Epoch 48/100\n",
      "20257/20257 [==============================] - 3s 142us/step - loss: 135.7610 - acc: 0.7928\n",
      "Epoch 49/100\n",
      "20257/20257 [==============================] - 3s 140us/step - loss: 135.7583 - acc: 0.7870\n",
      "Epoch 50/100\n",
      "20257/20257 [==============================] - 3s 142us/step - loss: 135.7653 - acc: 0.7943\n",
      "Epoch 51/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 135.7389 - acc: 0.7834\n",
      "Epoch 52/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.7419 - acc: 0.7912\n",
      "Epoch 53/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.7187 - acc: 0.7882\n",
      "Epoch 54/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.7243 - acc: 0.7950\n",
      "Epoch 55/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.7216 - acc: 0.7926\n",
      "Epoch 56/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 135.7060 - acc: 0.7892\n",
      "Epoch 57/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.6978 - acc: 0.7967\n",
      "Epoch 58/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 135.7013 - acc: 0.7959\n",
      "Epoch 59/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 135.6867 - acc: 0.8007\n",
      "Epoch 60/100\n",
      "20257/20257 [==============================] - 3s 143us/step - loss: 135.6816 - acc: 0.7952\n",
      "Epoch 61/100\n",
      "20257/20257 [==============================] - 3s 145us/step - loss: 135.6798 - acc: 0.7949\n",
      "Epoch 62/100\n",
      "20257/20257 [==============================] - 3s 143us/step - loss: 135.6629 - acc: 0.7974\n",
      "Epoch 63/100\n",
      "20257/20257 [==============================] - 3s 140us/step - loss: 135.6705 - acc: 0.7952\n",
      "Epoch 64/100\n",
      "20257/20257 [==============================] - 3s 140us/step - loss: 135.6593 - acc: 0.7979\n",
      "Epoch 65/100\n",
      "20257/20257 [==============================] - 3s 141us/step - loss: 135.6480 - acc: 0.7942\n",
      "Epoch 66/100\n",
      "20257/20257 [==============================] - 3s 145us/step - loss: 135.6486 - acc: 0.7966\n",
      "Epoch 67/100\n",
      "20257/20257 [==============================] - 3s 146us/step - loss: 135.6470 - acc: 0.7997\n",
      "Epoch 68/100\n",
      "20257/20257 [==============================] - 3s 138us/step - loss: 135.6312 - acc: 0.8051\n",
      "Epoch 69/100\n",
      "20257/20257 [==============================] - 3s 139us/step - loss: 135.6358 - acc: 0.8016\n",
      "Epoch 70/100\n",
      "20257/20257 [==============================] - 3s 139us/step - loss: 135.6319 - acc: 0.8024\n",
      "Epoch 71/100\n",
      "20257/20257 [==============================] - 3s 139us/step - loss: 135.6242 - acc: 0.7998\n",
      "Epoch 72/100\n",
      "20257/20257 [==============================] - 3s 139us/step - loss: 135.6232 - acc: 0.7998\n",
      "Epoch 73/100\n",
      "20257/20257 [==============================] - 3s 138us/step - loss: 135.6167 - acc: 0.8010\n",
      "Epoch 74/100\n",
      "20257/20257 [==============================] - 3s 138us/step - loss: 135.6341 - acc: 0.7978\n",
      "Epoch 75/100\n",
      "20257/20257 [==============================] - 3s 138us/step - loss: 135.6059 - acc: 0.8050\n",
      "Epoch 76/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 135.6096 - acc: 0.8072\n",
      "Epoch 77/100\n",
      "20257/20257 [==============================] - 3s 137us/step - loss: 135.6155 - acc: 0.8046\n",
      "Epoch 78/100\n",
      "20257/20257 [==============================] - 3s 137us/step - loss: 135.6047 - acc: 0.8055\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20257/20257 [==============================] - 3s 134us/step - loss: 135.6052 - acc: 0.8052\n",
      "Epoch 80/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 135.6025 - acc: 0.8054\n",
      "Epoch 81/100\n",
      "20257/20257 [==============================] - 3s 144us/step - loss: 135.5956 - acc: 0.8069\n",
      "Epoch 82/100\n",
      "20257/20257 [==============================] - 3s 134us/step - loss: 135.5888 - acc: 0.8054\n",
      "Epoch 83/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 135.5722 - acc: 0.8046\n",
      "Epoch 84/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.5791 - acc: 0.8113\n",
      "Epoch 85/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.5703 - acc: 0.8129\n",
      "Epoch 86/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.5816 - acc: 0.8117\n",
      "Epoch 87/100\n",
      "20257/20257 [==============================] - 3s 138us/step - loss: 135.5564 - acc: 0.8079\n",
      "Epoch 88/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.5723 - acc: 0.8074\n",
      "Epoch 89/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.5742 - acc: 0.8013\n",
      "Epoch 90/100\n",
      "20257/20257 [==============================] - 3s 134us/step - loss: 135.5618 - acc: 0.8039\n",
      "Epoch 91/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 135.5709 - acc: 0.8027\n",
      "Epoch 92/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.5556 - acc: 0.8060\n",
      "Epoch 93/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 135.5536 - acc: 0.8052\n",
      "Epoch 94/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.5466 - acc: 0.8052\n",
      "Epoch 95/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.5525 - acc: 0.8067\n",
      "Epoch 96/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.5586 - acc: 0.8086\n",
      "Epoch 97/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 135.5459 - acc: 0.8092\n",
      "Epoch 98/100\n",
      "20257/20257 [==============================] - 3s 136us/step - loss: 135.5507 - acc: 0.8050\n",
      "Epoch 99/100\n",
      "20257/20257 [==============================] - 3s 137us/step - loss: 135.5395 - acc: 0.8070\n",
      "Epoch 100/100\n",
      "20257/20257 [==============================] - 3s 135us/step - loss: 135.5251 - acc: 0.8120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f01885e72b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          batch_size=20, nb_epoch=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
